{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2640fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f3b6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigma(x):\n",
    "    return 1/(1+exp(-x))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def sigma_der(x):\n",
    "    return exp(-x)/((1+exp(-x))**2) # return sigma(x)*(1-sigma(x))\n",
    "\n",
    "# preparing data\n",
    "def prep(x_1,x_2):\n",
    "    return np.array([1,x_1,x_2])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a48ff",
   "metadata": {},
   "source": [
    "### Log-likelihood equation using cross entropy\n",
    "$$J(\\vec{w})=\\displaystyle\\sum_{i}y_ilog(p_1(\\vec{w},\\vec{x}_i))+(1-y_i)log(p_0(\\vec{w},\\vec{x}_i))$$\n",
    "where,\n",
    "$$p_1(\\vec{w},\\vec{x}_i)=\\sigma(\\vec{w}.\\vec{x}_i)$$\n",
    "$$p_0(\\vec{w},\\vec{x}_i)=1-\\sigma(\\vec{w}.\\vec{x}_i)$$\n",
    "### Maximising Log-likelihood is same as minimising -J(w)\n",
    "$$\\dfrac{d}{d\\vec{w}}(-J(\\vec{w}))=\\displaystyle\\sum_{i}(\\sigma(\\vec{w}.\\vec{x}_i)-y_i)\\vec{x}_i$$\n",
    "### Using Gradient-descent to find optimal parameters\n",
    "$$\\vec{w}^{(i+1)}=\\vec{w}^{(i)}-\\gamma\\dfrac{d}{d\\vec{w}}(-J(\\vec{w}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9f6a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing logistic regression using cross entropy and gradient descent\n",
    "def log_reg(X,Y,W_init,gamma):\n",
    "    \n",
    "    n=X.shape[0] # number of data\n",
    "    m=X.shape[1] # 1+number of features\n",
    "    w=W_init\n",
    "    a=0\n",
    "    \n",
    "    while(1):  \n",
    "        upd=0\n",
    "        for i in range(n):\n",
    "            z=w@X[i]\n",
    "            upd+=gamma*(sigma(z)-Y[i])*X[i]\n",
    "        change=np.linalg.norm(upd)\n",
    "        if(change>=1e-3):\n",
    "            w-=upd\n",
    "        else:\n",
    "            return w\n",
    "        if(a==0):\n",
    "            a+=1\n",
    "            print(\"after 1 iteration, weights are:\",w)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff9cc508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.346 0.78 ]\n",
      " [1.    0.303 0.439]\n",
      " [1.    0.358 0.729]\n",
      " [1.    0.602 0.863]\n",
      " [1.    0.79  0.753]\n",
      " [1.    0.611 0.965]]\n",
      "[[1.    0.959 0.382]\n",
      " [1.    0.75  0.306]\n",
      " [1.    0.395 0.76 ]\n",
      " [1.    0.823 0.764]\n",
      " [1.    0.761 0.874]\n",
      " [1.    0.844 0.435]]\n"
     ]
    }
   ],
   "source": [
    "tr_X=np.array([prep(0.346,0.78),prep(0.303,0.439),prep(0.358,0.729),prep(0.602,0.863),prep(0.790,0.753),prep(0.611,0.965)])\n",
    "print(tr_X)\n",
    "tr_Y=np.array([0,0,0,1,1,1])\n",
    "te_X=np.array([prep(0.959,0.382),prep(0.750,0.306),prep(0.395,0.760),prep(0.823,0.764),prep(0.761,0.874),prep(0.844,0.435)])\n",
    "te_Y=np.array([0,0,0,1,1,1])\n",
    "print(te_X)\n",
    "W=np.array([-1,1.5,0.5])\n",
    "lr_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d0c15b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 iteration, weights are: [-1.01899756  1.53210518  0.51181202]\n",
      "Final Weights are: [-18.07774125  26.47820683   6.58909946]\n",
      "Prediction: [1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "final_w=log_reg(tr_X,tr_Y,W,lr_rate)\n",
    "n=te_X.shape[0]\n",
    "y_pred=np.zeros(6)\n",
    "for i in range(n):\n",
    "    x=te_X[i]\n",
    "    z=final_w@x\n",
    "    if(sigma(z)>=0.5):\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "\n",
    "print('Final Weights are:',final_w)\n",
    "print(\"Prediction:\",y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24030ab5",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c5ee4",
   "metadata": {},
   "source": [
    "$$\\vec{w}=[-1, 1.5, 0.5]$$\n",
    "$$P(\\hat y=1|x_1,x_2)=\\dfrac{1}{1+e^{-(-1+1.5x_1+0.5x_2)}}$$\n",
    "$$P(\\hat y=0|x_1,x_2)=1-\\dfrac{1}{1+e^{-(-1+1.5x_1+0.5x_2)}}$$\n",
    "$$J(\\vec{w})=\\displaystyle\\sum_{i}y_ilog(P(\\hat y_i=1|\\vec{x}_i))+(1-y_i)log(P(\\hat y_i=0|\\vec{x}_i))$$\n",
    "where\n",
    "$$\\vec{x}=[1,x_1,x_2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0728d",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c02738",
   "metadata": {},
   "source": [
    "$$\\vec{w}=[-1.01899756,  1.53210518,  0.51181202]$$\n",
    "$$P(\\hat y=1|x_1,x_2)=\\dfrac{1}{1+e^{-(-1.01899756+1.53210518x_1+0.51181202x_2)}}$$\n",
    "$$P(\\hat y=0|x_1,x_2)=1-\\dfrac{1}{1+e^{-(-1.01899756+1.53210518x_1+0.51181202x_2)}}$$\n",
    "$$J(\\vec{w})=\\displaystyle\\sum_{i}y_ilog(P(\\hat y_i=1|\\vec{x}_i))+(1-y_i)log(P(\\hat y_i=0|\\vec{x}_i))$$\n",
    "where\n",
    "$$\\vec{x}=[1,x_1,x_2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d2c31",
   "metadata": {},
   "source": [
    "### c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49742325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tolerance of 10^{-3}, gradient descent converges to the weights: [-18.07774125, 26.47820683, 6.58909946]\n",
      "Actual y: [0.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "Prediction: [1.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n",
      "Accuracy=(TP+TN)/(TP+TN+FP+FN)=4/6=0.67\n",
      "Precision=TP/(TP+FP)=3/5=0.6\n",
      "Recall=TP/(TP+FN)=3/3=1\n"
     ]
    }
   ],
   "source": [
    "print('For tolerance of 10^{-3}, gradient descent converges to the weights:',[-18.07774125,26.47820683,6.58909946])\n",
    "print('Actual y:',[0, 0, 0, 1, 1, 1])\n",
    "print('Prediction:',[1, 1, 0, 1, 1, 1])\n",
    "print('Accuracy=(TP+TN)/(TP+TN+FP+FN)=4/6=0.67')\n",
    "print('Precision=TP/(TP+FP)=3/5=0.6')\n",
    "print('Recall=TP/(TP+FN)=3/3=1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
